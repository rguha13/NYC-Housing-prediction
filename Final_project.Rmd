---
title: "STAT 692 Final Project: NYC Housing market price modeling by location"
author: "Riana Guha"
date: "Spring 2024"
output:
  pdf_document: default
  html_document: 
    toc: yes
urlcolor: cyan
---

# Introduction

The main aim of this project is to model the NYC housing data to determine the optimal house price. I will also be focusing on the house location and it's importance in the price. The dataset is avaliable on kaggle - https://www.kaggle.com/datasets/nelgiriyewithana/new-york-housing-market/data

Project objectives:
Price Analysis: find the ideal price range for houses using predictive modeling. This will provide insights for investors and real estate agents to make informed decisions before purchasing a house in NYC.

Location Analysis: Analyze the importance of house location (neighborhoods, districts, regions).

Key Features:
-`BROKERTITLE`: Title of the broker
-`TYPE`: Type of the house
-`PRICE`: Price of the house
-`BEDS`: Number of bedrooms
-`BATH`: Number of bathrooms
-`PROPERTYSQFT`: Square footage of the property
-`ADDRESS`: Full address of the house
-`STATE`: State of the house
-`MAIN_ADDRESS`: Main address information
-`ADMINISTRATIVE_AREA_LEVEL_2`: Administrative area level 2 information
-`LOCALITY`: Locality information
-`SUBLOCALITY`: Sublocality information
-`STREET_NAME`: Street name
-`LONG_NAME`: Long name
-`FORMATTED_ADDRESS`: Formatted address
-`LATITUDE`: Latitude coordinate of the house
-`LONGITUDE`: Longitude coordinate of the house


## Loading the required packages
```{r, warning = FALSE}
require(tidyverse)
library(ggplot2)
library(scales)
library(corrplot)
library(caret)
library(boot)
library(MASS)
library(randomForest)
library(tree)
```


## Data exploration and cleaning
```{r}
data <- read.csv("NY-House-Dataset.csv")
#str(data) # structure of dataset
#dim(data) # the dataset contains 4801 rows and 17 columns
colSums(is.na(data)) # checking for missing values per column - No missing values

data_filtered = data[,c('PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT', 'SUBLOCALITY', 'STREET_NAME', 'LONG_NAME')] # filtering data to keep relevant columns
#colnames(data_filtered) # verifying column names
dim(data_filtered) # it is now a 4801x12 dataset
head(data_filtered)
```


## EDA (Exploratory Data Analysis)
```{r}
summary(data_filtered[, c('PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT')]) # summary statistics for numeric variables
```

**Insights:**
Price:
The average house price is around 2.357 million. This suggests that the houses are quite expensive. The minimum price is 2494 which is quite low and the high is 2.147 billion which is extremely high. This shows quite a drastic range in house prices.

Bed and Bath:
The average house size is 3.357 beds and 2.374 baths (3 bed 2 bath). The minimum is 1 bed and no bath (could be an underdeveloped property), and the maximum is 50 beds and 50 baths (this could be a shared development/ apartment complex).

Property size (in sqft):
The average property size is 2184 sqft which is quite large. The minimum is 230 sqft and maximum is 65535 sqft which shows a large range of property sizes.

### Scatter plots of our target variables vs. PRICE
```{r}
par(mfrow = c(1,3))
plot(data_filtered$PROPERTYSQFT, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "blue")
plot(data_filtered$BEDS, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "green")
plot(data_filtered$BATH, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "orange")
```

### Histograms for all of our target variables - PRICE, BATH, BEDS, PROPERTYSQFT
```{r}
par(mfrow=c(2, 2))  # Set up a 2x2 grid for subplots

# Histogram for 'PRICE'
hist(data_filtered$PRICE, main = "Histogram of Price", ylab = "Frequency", col = "skyblue")

# Histogram for 'BEDS'
hist(data_filtered$BEDS, main = "Histogram of Beds", ylab = "Frequency", col = "green")

# Histogram for 'BATH'
hist(data_filtered$BATH, main = "Histogram of Baths", ylab = "Frequency", col = "orange")

# Histogram for 'PROPERTYSQFT'
hist(data_filtered$PROPERTYSQFT, main = "Histogram of Property Size", ylab = "Frequency", col = "pink")
```

We can tell from these graphs that there is evidence of outliers in the data which does not follow the overall distribution of the data. Let us remove any outliers for this analysis and keep all the values which are within the IQR. We first find the first and third quantiles and then we calculate the upper and lower limits for the outliers (threshold). 

### Outlier Removal
```{r}
remove_outliers <- function(data, variables, threshold = 1.5) {
  for (variable in variables) {
    Q1 <- quantile(data[[variable]], 0.25)
    Q3 <- quantile(data[[variable]], 0.75)
    IQR <- Q3 - Q1
    data <- data[!(data[[variable]] > (Q3 + threshold * IQR) | data[[variable]] < (Q1 - threshold * IQR)), ]
  }
  return(data)
}

# variables for which we want to remove outliers
variables_out <- c('PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT')

data_filtered <- remove_outliers(data_filtered, variables_out)
```

Visualizing the histograms for all of our target variables - PRICE, BATH, BEDS, PROPERTYSQFT once the outliers have been removed.
```{r}
par(mfrow=c(2, 2))  # Set up a 2x2 grid for subplots

# Histogram for 'PRICE'
hist(data_filtered$PRICE, main = "Histogram of Price", ylab = "Frequency", col = "skyblue")

# Histogram for 'BEDS'
hist(data_filtered$BEDS, main = "Histogram of Beds", ylab = "Frequency", col = "green")

# Histogram for 'BATH'
hist(data_filtered$BATH, main = "Histogram of Baths", ylab = "Frequency", col = "orange")

# Histogram for 'PROPERTYSQFT'
hist(data_filtered$PROPERTYSQFT, main = "Histogram of Property Size", ylab = "Frequency", col = "pink")
```

Let's visualize the scatter plot now that the outliers are removed
```{r}
par(mfrow = c(1,3))
plot(data_filtered$PROPERTYSQFT, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "blue")
plot(data_filtered$BEDS, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "green")
plot(data_filtered$BATH, data_filtered$PRICE, 
     main = "Price vs. Property Size",
     xlab = "Property Size (Sqft)",
     ylab = "Price",
     col = "orange")

```


### Grouping data by SUBLOCALITY and finding the mean of other features
```{r}
grouped_sublocality <- data_filtered %>%
  group_by(SUBLOCALITY) %>%
  summarise(
    Mean_Price = mean(PRICE),
    Mean_Beds = mean(BEDS),
    Mean_Bath = mean(BATH),
    Mean_PropertySqft = mean(PROPERTYSQFT)
  )%>%
  arrange(desc(Mean_Price))

head(grouped_sublocality) # data by sub-locality in NYC and arranges in descending price
```

**Insights**
New York County has the highest mean price of houses in the dataset and Rego Park has the lowest mean prices of houses in the dataset.

Modifying the dataset for easier plotting
```{r}
grouped_sublocality_df <- data.frame(
  Sublocality = grouped_sublocality$SUBLOCALITY,
  Avg_Price = round(grouped_sublocality$Mean_Price / 10^6, 2),
  Avg_Beds = round(grouped_sublocality$Mean_Beds, 2),
  Avg_Baths = round(grouped_sublocality$Mean_Bath, 2),
  Avg_PropertySqft = round(grouped_sublocality$Mean_PropertySqft)
)
head(grouped_sublocality_df, 10)
```

### EDA plots
```{r}
sublocalities_plot_price <- grouped_sublocality_df %>%
  head(10) %>%
  ggplot(aes(x = reorder(Sublocality, -Avg_Price), y = Avg_Price, fill = Sublocality)) +
  geom_bar(stat = "identity", color = "black") +
  labs(title = "Top 10 Sublocalities by Average Price",
       x = "Sublocality",
       y = "Average Price (Millions)")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

sublocalities_plot_price
```

### Filtering data for key ares - New York County, Manhattan, Brooklyn, Dumbo
```{r}
#specifying key areas
key_areas <- c('New York County', 'Dumbo', 'Manhattan', 'Brooklyn') 

# Filtering data for selected key areas
areas_data <- data_filtered[data_filtered$SUBLOCALITY %in% key_areas, ]

ggplot(areas_data, aes(x = SUBLOCALITY, y = PRICE)) +
  geom_boxplot(fill = "skyblue") +
  labs(title = 'Price Distribution in Key NYC Areas',
       x = 'Sublocality',
       y = 'log price') +
  theme_minimal() +
  scale_y_continuous(labels = scales::dollar_format(), trans = 'log')
```

## Correlation analysis
```{r}
# Selecting columns for correlation analysis
corr_columns <- c('PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT')

# Correlation Analysis
correlation <- cor(data_filtered[corr_columns])

# Plotting the correlation matrix
corrplot(correlation, method = 'number', col = colorRampPalette(c('darkgreen', 'white', 'blue'))(20))
title('Correlation Matrix with Coefficients')
```

**Insights**

# Predictive Modeling

Visualizing the number of distinct values in each column of the filtered dataset
```{r}
distinct_value_counts <- sapply(data_filtered, function(col) length(unique(col)))
distinct_value_counts
```

Display unique value counts for the top 5 values in each column
```{r}
unique_value_counts <- lapply(data_filtered, function(col) head(table(col), 5))
unique_value_counts
```

Standardize the 'PRICE' column 
```{r}
data_filtered$PRICE_standardized <- scale(data_filtered$PRICE)

#Sorting the DataFrame by 'PRICE_standardized' in descending order
sorted_data <- data_filtered[order(-data_filtered$PRICE_standardized), ]

# Exclude the top 2 rows
sorted_data <- sorted_data[-(1:2), ]

head(sorted_data[,c("PRICE", "PRICE_standardized")])

#dimensions of the sorted data
dim(sorted_data) 
```

Grouping for sub-locality using the sorted data and generating a boxplot of prices for each sublocality.
```{r}
ggplot(data_filtered, aes(x = SUBLOCALITY, y = PRICE_standardized)) +
  geom_boxplot(outlier.shape = NA) +  # Removing outliers from the plot
  labs(title = 'Boxplot of Prices for Each Sublocality (Adjusted for Outliers)',
       x = 'SUBLOCALITY',
       y = 'PRICE') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

Calculating average price by sublocality for the sorted data
```{r}
average_prices <- sorted_data %>%
  group_by(SUBLOCALITY) %>%
  summarise(Average_Price = mean(PRICE, na.rm = TRUE))

ggplot(average_prices, aes(x = SUBLOCALITY, y = Average_Price, fill = SUBLOCALITY)) +
  geom_bar(stat = "identity") +
  labs(title = 'Average Prices by Sublocality',
       x = 'Sublocality',
       y = 'Average Price') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = 'none')

```

Encoding categorical variables
```{r}
data_filtered$SUBLOCALITY_encoded <- as.integer(as.factor(data_filtered$SUBLOCALITY))
```

Selecting the features (X) and the target (Y)
```{r}
X <- data_filtered[, c('SUBLOCALITY_encoded', 'BEDS', 'BATH', 'PROPERTYSQFT')]
Y <- data_filtered$PRICE_standardized
```

Splitting the data into training and testing sets
```{r}
set.seed(42)
train_indices <- createDataPartition(Y, p = 0.8, list = FALSE)
train_data <- data_filtered[train_indices, ]
test_data <- data_filtered[-train_indices, ]

# testing set
X_test <- test_data[, c('SUBLOCALITY_encoded', 'BEDS', 'BATH', 'PROPERTYSQFT')]
Y_test <- test_data$PRICE

# training set
X_train <- train_data[, c('SUBLOCALITY_encoded', 'BEDS', 'BATH', 'PROPERTYSQFT')]
Y_train <- train_data$PRICE
```

# Random Forest Classifer 
```{r}
rf_model <- randomForest(PRICE_standardized ~ ., data = train_data, ntree = 100)
print(rf_model)
```

Now we can use the trained model to make predictions based on the test set
```{r}
rf_predictions <- predict(rf_model, newdata = test_data)

# Evaluate the performance of the Random Forest model
rf_mse <- mean((rf_predictions - test_data$PRICE_standardized)^2)
rf_rmse <- sqrt(rf_mse)
rf_r_squared <- 1 - (rf_mse / var(test_data$PRICE))

cat("Mean Squared Error (MSE):", rf_mse, "\n")
cat("Root Mean Squared Error (RMSE):", rf_rmse, "\n")
cat("R-squared:", rf_r_squared, "\n")
```

**Insights:** 
- Low MSE and RMSE: A low MSE and RMSE indicate that the model's predictions are close to the actual values. 
- R-squared: An R-squared of 1 indicates that the model perfectly predicts the variation in the target variable.


# Inferences

Visualizing the predicted values against the actual values to see how well the model aligns with the true outcomes.
```{r}
plot(test_data$PRICE_standardized, rf_predictions, 
     main = "Actual vs. Predicted Prices",
     xlab = "Actual Prices",
     ylab = "Predicted Prices",
     col = "blue")
abline(0, 1, col = "red")
```

Residual Analysis
```{r}
residuals <- rf_predictions - test_data$PRICE_standardized
plot(rf_predictions, residuals, 
     main = "Residual Analysis",
     xlab = "Predicted Prices",
     ylab = "Residuals",
     col = "green")
abline(h = 0, col = "red")
```

Feature Importance
```{r}
varImpPlot(rf_model, main = "Variable Importance Plot")
```



